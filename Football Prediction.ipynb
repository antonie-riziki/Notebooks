{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Outcome Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import autoreload\n",
    "import missingno as msno\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'samples/sample.netrc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetrc\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read the .netrc file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m netrc_info \u001b[38;5;241m=\u001b[39m \u001b[43mnetrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetrc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msamples/sample.netrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get the login information for a specific host\u001b[39;00m\n\u001b[0;32m      7\u001b[0m login, account, password \u001b[38;5;241m=\u001b[39m netrc_info\u001b[38;5;241m.\u001b[39mauthenticators(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecret.fbi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\netrc.py:74\u001b[0m, in \u001b[0;36mnetrc.__init__\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmacros \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(file, fp, default_netrc)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'samples/sample.netrc'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import netrc\n",
    "\n",
    "# Read the .netrc file\n",
    "netrc_info = netrc.netrc(\"samples/sample.netrc\")\n",
    "\n",
    "# Get the login information for a specific host\n",
    "login, account, password = netrc_info.authenticators(\"secret.fbi\")\n",
    "\n",
    "# Print the retrieved information\n",
    "print(\"login:\", login)\n",
    "print(\"account:\", account)\n",
    "print(\"password:\", password)\n",
    "\n",
    "\n",
    "\n",
    "from espn_api.football import League\n",
    "# Instantiate the League class\n",
    "league = League(league_id=222, year=2022)\n",
    "\n",
    "# Provide a valid team_id as an argument to get_team_data() method\n",
    "team_id = \"your_team_id_here\"\n",
    "team_data = league.get_team_data(team_id)\n",
    "\n",
    "# Access the desired information from the team_data object\n",
    "# For example, print the team name\n",
    "print(team_data[\"team_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\anton\\\\.netrc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetrc\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get the host name and login credentials from the .netrc file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[43mnetrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetrc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mauthenticators(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.football-data.org\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Construct the headers dictionary with the X-Auth-Token value\u001b[39;00m\n\u001b[0;32m      7\u001b[0m headers \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-Auth-Token\u001b[39m\u001b[38;5;124m'\u001b[39m: auth[\u001b[38;5;241m2\u001b[39m] }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\netrc.py:74\u001b[0m, in \u001b[0;36mnetrc.__init__\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmacros \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(file, fp, default_netrc)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\anton\\\\.netrc'"
     ]
    }
   ],
   "source": [
    "import netrc\n",
    "\n",
    "# Get the host name and login credentials from the .netrc file\n",
    "auth = netrc.netrc().authenticators(\"https://api.football-data.org\")\n",
    "\n",
    "# Construct the headers dictionary with the X-Auth-Token value\n",
    "headers = { 'X-Auth-Token': auth[2] }\n",
    "\n",
    "# Make the API request with the headers dictionary\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Process the response data\n",
    "for match in response.json()['matches']:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_name\u001b[39m\u001b[38;5;124m'\u001b[39m: team_names,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_form\u001b[39m\u001b[38;5;124m'\u001b[39m: current_form,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minjury_news\u001b[39m\u001b[38;5;124m'\u001b[39m: injury_news\n\u001b[0;32m     18\u001b[0m })\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Clean the data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_form\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_form\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Handle missing values\u001b[39;00m\n\u001b[0;32m     24\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Step 1: Scraping data from a website\n",
    "\n",
    "url = 'https://sportsdata.io/scores-and-stats'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract relevant information from the HTML structure\n",
    "team_names = [element.text for element in soup.find_all('div', class_='team-name')]\n",
    "current_form = [element.text for element in soup.find_all('div', class_='form')]\n",
    "injury_news = [element.text for element in soup.find_all('div', class_='injuries')]\n",
    "\n",
    "\n",
    "# Create a DataFrame with the extracted data\n",
    "data = pd.DataFrame({\n",
    "    'team_name': team_names,\n",
    "    'current_form': current_form,\n",
    "    'injury_news': injury_news\n",
    "})\n",
    "\n",
    "# Clean the data\n",
    "data['current_form'] = data['current_form'].str.extract('(\\d+)', expand=False).astype(int)\n",
    "\n",
    "# Handle missing values\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data[['current_form']])\n",
    "\n",
    "# Step 3: Train machine learning models\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, data['team_name'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Train decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Train random forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train neural network model\n",
    "nn_model = MLPClassifier(random_state=42)\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate logistic regression model\n",
    "logreg_pred = logreg_model.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_pred)\n",
    "logreg_precision = precision_score(y_test, logreg_pred, average='weighted')\n",
    "logreg_recall = recall_score(y_test, logreg_pred, average='weighted')\n",
    "logreg_f1_score = f1_score(y_test, logreg_pred, average='weighted')\n",
    "\n",
    "# Evaluate decision tree model\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "dt_precision = precision_score(y_test, dt_pred, average='weighted')\n",
    "dt_recall = recall_score(y_test, dt_pred, average='weighted')\n",
    "dt_f1_score = f1_score(y_test, dt_pred, average='weighted')\n",
    "\n",
    "# Evaluate random forest model\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_pred, average='weighted')\n",
    "rf_f1_score = f1_score(y_test, rf_pred, average='weighted')\n",
    "\n",
    "# Evaluate neural network model\n",
    "nn_pred = nn_model.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "nn_precision = precision_score(y_test, nn_pred, average='weighted')\n",
    "nn_recall = recall_score(y_test, nn_pred, average='weighted')\n",
    "nn_f1_score = f1_score(y_test, nn_pred, average='weighted')\n",
    "\n",
    "# Step 5: Select the best model\n",
    "model_scores = {\n",
    "    'logreg': logreg_accuracy,\n",
    "    'dt': dt_accuracy,\n",
    "    'rf': rf_accuracy,\n",
    "    'nn': nn_accuracy\n",
    "}\n",
    "\n",
    "best_model = max(model_scores, key=model_scores.get)\n",
    "print('Best model:', best_model)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "# You can use the best model to make predictions on new data\n",
    "# For example:\n",
    "new_data = pd.DataFrame({\n",
    "    'team_name': ['Team A', 'Team B'],\n",
    "    'current_form': [3, 2],\n",
    "    'injury_news': ['No injuries', '1 player out']\n",
    "})\n",
    "\n",
    "# Clean and transform the new data\n",
    "new_data['current_form'] = new_data['current_form'].astype(int)\n",
    "new_data = new_data.fillna(0)\n",
    "new_scaled_data = scaler.transform(new_data[['current_form']])\n",
    "\n",
    "# Make predictions using the best model\n",
    "if best_model == 'logreg':\n",
    "    prediction = logreg_model.predict(new_scaled_data)\n",
    "elif best_model == 'dt':\n",
    "    prediction = dt_model.predict(new_scaled_data)\n",
    "elif best_model == 'rf':\n",
    "    prediction = rf_model.predict(new_scaled_data)\n",
    "elif best_model == 'nn':\n",
    "    prediction = nn_model.predict(new_scaled_data)\n",
    "\n",
    "print('Prediction:', prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
